# å®¢æˆ·ç«¯é›†æˆç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›å„ç§ç¼–ç¨‹è¯­è¨€å’Œå®¢æˆ·ç«¯å·¥å…·é›†æˆ AI Studio Proxy API çš„ç¤ºä¾‹ä»£ç ã€‚

---

## ğŸ“‹ ç›®å½•

- [cURL å‘½ä»¤è¡Œ](#curl-å‘½ä»¤è¡Œ)
- [Python](#python)
- [JavaScript / Node.js](#javascript--nodejs)
- [å®¢æˆ·ç«¯å·¥å…·](#å®¢æˆ·ç«¯å·¥å…·)

---

## cURL å‘½ä»¤è¡Œ

### å¥åº·æ£€æŸ¥

```bash
curl http://127.0.0.1:2048/health
```

### è·å–æ¨¡å‹åˆ—è¡¨

```bash
curl http://127.0.0.1:2048/v1/models
```

### éæµå¼èŠå¤©è¯·æ±‚

```bash
curl -X POST http://127.0.0.1:2048/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "gemini-1.5-pro",
    "messages": [
      {
        "role": "user",
        "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"
      }
    ],
    "stream": false,
    "temperature": 0.7,
    "max_output_tokens": 2048
  }'
```

### æµå¼èŠå¤©è¯·æ±‚ (SSE)

```bash
curl -X POST http://127.0.0.1:2048/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "gemini-1.5-flash",
    "messages": [
      {
        "role": "user",
        "content": "è¯·è®²ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½çš„æ•…äº‹"
      }
    ],
    "stream": true
  }' --no-buffer
```

### å¸¦å‚æ•°çš„è¯·æ±‚

```bash
curl -X POST http://127.0.0.1:2048/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-1.5-pro",
    "messages": [
      {
        "role": "system",
        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Python å¼€å‘è€…"
      },
      {
        "role": "user",
        "content": "å¦‚ä½•ä½¿ç”¨ asyncio å®ç°å¹¶å‘?"
      }
    ],
    "stream": false,
    "temperature": 0.5,
    "max_output_tokens": 4096,
    "top_p": 0.9,
    "stop": ["\n\nUser:", "\n\nAssistant:"]
  }'
```

---

## Python

### ä½¿ç”¨ OpenAI SDK

#### å®‰è£…

```bash
pip install openai
```

#### åŸºæœ¬ç”¨æ³•

```python
from openai import OpenAI

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    base_url="http://127.0.0.1:2048/v1",
    api_key="your-api-key"  # å¦‚æœæœåŠ¡å™¨ä¸éœ€è¦è®¤è¯ï¼Œå¯ä»¥æ˜¯ä»»æ„å€¼
)

# éæµå¼è¯·æ±‚
def basic_chat():
    response = client.chat.completions.create(
        model="gemini-1.5-pro",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"},
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯ FastAPI?"}
        ]
    )

    print(response.choices[0].message.content)

basic_chat()
```

#### æµå¼å“åº”

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://127.0.0.1:2048/v1",
    api_key="your-api-key"
)

def streaming_chat():
    stream = client.chat.completions.create(
        model="gemini-1.5-pro",
        messages=[
            {"role": "user", "content": "è¯·è®²ä¸€ä¸ªå…³äºæœºå™¨å­¦ä¹ çš„æ•…äº‹"}
        ],
        stream=True
    )

    print("AI: ", end="", flush=True)
    for chunk in stream:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
    print()  # æ¢è¡Œ

streaming_chat()
```

#### å¸¦å‚æ•°çš„è¯·æ±‚

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://127.0.0.1:2048/v1",
    api_key="your-api-key"
)

def advanced_chat():
    response = client.chat.completions.create(
        model="gemini-1.5-pro",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª Python ä¸“å®¶"},
            {"role": "user", "content": "è§£é‡Šè£…é¥°å™¨çš„å·¥ä½œåŸç†"}
        ],
        temperature=0.7,
        max_tokens=2048,
        top_p=0.9,
        stop=["\n\nç”¨æˆ·:", "\n\nåŠ©æ‰‹:"]
    )

    print(response.choices[0].message.content)
    print(f"\nä½¿ç”¨çš„ tokens: {response.usage.total_tokens}")

advanced_chat()
```

#### é”™è¯¯å¤„ç†

```python
from openai import OpenAI, APIError, APIConnectionError
import time

client = OpenAI(
    base_url="http://127.0.0.1:2048/v1",
    api_key="your-api-key",
    timeout=60.0
)

def chat_with_retry(messages, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„èŠå¤©"""
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gemini-1.5-pro",
                messages=messages
            )
            return response.choices[0].message.content

        except APIConnectionError as e:
            print(f"è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                continue
            raise

        except APIError as e:
            print(f"API é”™è¯¯: {e}")
            raise

# ä½¿ç”¨ç¤ºä¾‹
try:
    result = chat_with_retry([
        {"role": "user", "content": "ä½ å¥½"}
    ])
    print(result)
except Exception as e:
    print(f"è¯·æ±‚å¤±è´¥: {e}")
```

### ä½¿ç”¨ requests åº“

#### å®‰è£…

```bash
pip install requests
```

#### éæµå¼è¯·æ±‚

```python
import requests
import json

def chat_non_streaming():
    url = "http://127.0.0.1:2048/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer your-api-key"
    }
    data = {
        "model": "gemini-1.5-pro",
        "messages": [
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ?"}
        ],
        "stream": False
    }

    response = requests.post(url, headers=headers, json=data)

    if response.status_code == 200:
        result = response.json()
        print(result['choices'][0]['message']['content'])
    else:
        print(f"é”™è¯¯ {response.status_code}: {response.text}")

chat_non_streaming()
```

#### æµå¼è¯·æ±‚ (SSE)

```python
import requests
import json

def chat_streaming():
    url = "http://127.0.0.1:2048/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer your-api-key"
    }
    data = {
        "model": "gemini-1.5-pro",
        "messages": [
            {"role": "user", "content": "è¯·è®²ä¸€ä¸ªæ•…äº‹"}
        ],
        "stream": True
    }

    response = requests.post(url, headers=headers, json=data, stream=True)

    print("AI: ", end="", flush=True)
    for line in response.iter_lines():
        if line:
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€

                if data_str.strip() == '[DONE]':
                    print("\n")
                    break

                try:
                    chunk = json.loads(data_str)
                    if 'choices' in chunk:
                        delta = chunk['choices'][0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            print(content, end="", flush=True)
                except json.JSONDecodeError:
                    continue

chat_streaming()
```

---

## JavaScript / Node.js

> **æ³¨æ„**: ä»¥ä¸‹ä»£ç ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½œä¸º**å®¢æˆ·ç«¯**è¿æ¥åˆ° AI Studio Proxy APIã€‚è¿™äº›ä»£ç æ—¨åœ¨æ‚¨çš„åº”ç”¨ç¨‹åºä¸­è¿è¡Œï¼Œç”¨äºå‘ Proxy æœåŠ¡å™¨å‘é€è¯·æ±‚ï¼Œè€Œä¸æ˜¯ä½œä¸ºæœåŠ¡å™¨ä»£ç è¿è¡Œã€‚

### ä½¿ç”¨ OpenAI SDK

#### å®‰è£…

```bash
npm install openai
```

#### åŸºæœ¬ç”¨æ³•

```javascript
// æ³¨æ„ï¼šæ­¤ç¤ºä¾‹ä½¿ç”¨ ES Modules è¯­æ³•ã€‚
// å¦‚æœæ‚¨ä½¿ç”¨ CommonJS (require)ï¼Œè¯·æ”¹ç”¨: const OpenAI = require('openai');
import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://127.0.0.1:2048/v1",
  apiKey: "your-api-key",
});

// éæµå¼è¯·æ±‚
async function basicChat() {
  const response = await client.chat.completions.create({
    model: "gemini-1.5-pro",
    messages: [
      { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹" },
      { role: "user", content: "ä»€ä¹ˆæ˜¯ Node.js?" },
    ],
  });

  console.log(response.choices[0].message.content);
}

basicChat();
```

#### æµå¼å“åº”

```javascript
import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://127.0.0.1:2048/v1",
  apiKey: "your-api-key",
});

async function streamingChat() {
  const stream = await client.chat.completions.create({
    model: "gemini-1.5-pro",
    messages: [{ role: "user", content: "è¯·è®²ä¸€ä¸ªå…³äºç¼–ç¨‹çš„æ•…äº‹" }],
    stream: true,
  });

  process.stdout.write("AI: ");
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || "";
    process.stdout.write(content);
  }
  console.log("\n");
}

streamingChat();
```

#### é”™è¯¯å¤„ç†

```javascript
import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://127.0.0.1:2048/v1",
  apiKey: "your-api-key",
  timeout: 60 * 1000, // 60ç§’è¶…æ—¶
});

async function chatWithRetry(messages, maxRetries = 3) {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = await client.chat.completions.create({
        model: "gemini-1.5-pro",
        messages: messages,
      });

      return response.choices[0].message.content;
    } catch (error) {
      console.error(`å°è¯• ${attempt + 1}/${maxRetries} å¤±è´¥:`, error.message);

      if (attempt < maxRetries - 1) {
        // æŒ‡æ•°é€€é¿
        await new Promise((resolve) =>
          setTimeout(resolve, 2 ** attempt * 1000),
        );
        continue;
      }

      throw error;
    }
  }
}

// ä½¿ç”¨ç¤ºä¾‹
chatWithRetry([{ role: "user", content: "ä½ å¥½" }])
  .then((result) => {
    console.log(result);
  })
  .catch((error) => {
    console.error("è¯·æ±‚å¤±è´¥:", error);
  });
```

### ä½¿ç”¨ Fetch API

> **æ³¨æ„**: Node.js 18+ å†…ç½®äº† fetch APIã€‚å¦‚æœæ‚¨ä½¿ç”¨æ—§ç‰ˆæœ¬ï¼Œå¯èƒ½éœ€è¦å®‰è£… `node-fetch`ã€‚

```javascript
// éæµå¼è¯·æ±‚
async function chatNonStreaming() {
  const response = await fetch("http://127.0.0.1:2048/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: "Bearer your-api-key",
    },
    body: JSON.stringify({
      model: "gemini-1.5-pro",
      messages: [{ role: "user", content: "ä»€ä¹ˆæ˜¯ JavaScript?" }],
      stream: false,
    }),
  });

  const data = await response.json();
  console.log(data.choices[0].message.content);
}

// æµå¼è¯·æ±‚
async function chatStreaming() {
  const response = await fetch("http://127.0.0.1:2048/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: "Bearer your-api-key",
    },
    body: JSON.stringify({
      model: "gemini-1.5-pro",
      messages: [{ role: "user", content: "è¯·è®²ä¸€ä¸ªæ•…äº‹" }],
      stream: true,
    }),
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  process.stdout.write("AI: ");
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value);
    const lines = chunk.split("\n");

    for (const line of lines) {
      if (line.startsWith("data: ")) {
        const data = line.slice(6);
        if (data.trim() === "[DONE]") {
          console.log("\n");
          return;
        }

        try {
          const parsed = JSON.parse(data);
          const content = parsed.choices[0]?.delta?.content || "";
          process.stdout.write(content);
        } catch (e) {
          // å¿½ç•¥è§£æé”™è¯¯
        }
      }
    }
  }
}

chatNonStreaming();
chatStreaming();
```

---

## å®¢æˆ·ç«¯å·¥å…·

### Open WebUI

**é…ç½®æ­¥éª¤**:

1. æ‰“å¼€ Open WebUI
2. è¿›å…¥ "è®¾ç½®" â†’ "è¿æ¥"
3. åœ¨ "æ¨¡å‹" éƒ¨åˆ†ï¼Œç‚¹å‡» "æ·»åŠ æ¨¡å‹"
4. é…ç½®å¦‚ä¸‹:
   - **æ¨¡å‹åç§°**: `aistudio-gemini`
   - **API åŸºç¡€ URL**: `http://127.0.0.1:2048/v1`
   - **API å¯†é’¥**: è¾“å…¥æœ‰æ•ˆå¯†é’¥æˆ–ç•™ç©ºï¼ˆæ ¹æ®æœåŠ¡å™¨é…ç½®ï¼‰
5. ä¿å­˜è®¾ç½®

### ChatBox

**é…ç½®æ­¥éª¤**:

1. æ‰“å¼€ ChatBox
2. è¿›å…¥ "è®¾ç½®" â†’ "AI æä¾›å•†"
3. é€‰æ‹© "OpenAI API"
4. é…ç½®å¦‚ä¸‹:
   - **API åŸŸå**: `http://127.0.0.1:2048`
   - **API å¯†é’¥**: è¾“å…¥æœ‰æ•ˆå¯†é’¥
   - **æ¨¡å‹**: ä»ä¸‹æ‹‰åˆ—è¡¨é€‰æ‹©æ¨¡å‹
5. ä¿å­˜è®¾ç½®

### LobeChat

**é…ç½®æ­¥éª¤**:

1. æ‰“å¼€ LobeChat
2. ç‚¹å‡»å³ä¸Šè§’è®¾ç½®å›¾æ ‡
3. è¿›å…¥ "è¯­è¨€æ¨¡å‹" è®¾ç½®
4. é€‰æ‹© "OpenAI"
5. é…ç½®å¦‚ä¸‹:
   - **API åœ°å€**: `http://127.0.0.1:2048/v1`
   - **API Key**: è¾“å…¥æœ‰æ•ˆå¯†é’¥
6. ä¿å­˜è®¾ç½®

### Continue (VS Code æ‰©å±•)

**é…ç½®æ­¥éª¤**:

1. åœ¨ VS Code ä¸­å®‰è£… Continue æ‰©å±•
2. æ‰“å¼€ Continue è®¾ç½® (JSON)
3. æ·»åŠ é…ç½®:

```json
{
  "models": [
    {
      "title": "AI Studio Gemini",
      "provider": "openai",
      "model": "gemini-1.5-pro",
      "apiBase": "http://127.0.0.1:2048/v1",
      "apiKey": "your-api-key"
    }
  ]
}
```

4. ä¿å­˜å¹¶é‡è½½ VS Code

---

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

å§‹ç»ˆå®ç°é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶ï¼š

```python
def robust_chat(client, messages, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gemini-1.5-pro",
                messages=messages,
                timeout=60
            )
            return response
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            time.sleep(2 ** attempt)
```

### 2. è¶…æ—¶è®¾ç½®

ä¸ºè¯·æ±‚è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´ï¼š

```python
client = OpenAI(
    base_url="http://127.0.0.1:2048/v1",
    api_key="your-api-key",
    timeout=60.0  # 60ç§’è¶…æ—¶
)
```

### 3. æµå¼å¤„ç†

å¯¹äºé•¿æ–‡æœ¬ç”Ÿæˆï¼Œä¼˜å…ˆä½¿ç”¨æµå¼å“åº”ï¼š

```python
stream = client.chat.completions.create(
    model="gemini-1.5-pro",
    messages=[{"role": "user", "content": "å†™ä¸€ç¯‡é•¿æ–‡"}],
    stream=True
)

for chunk in stream:
    content = chunk.choices[0].delta.content
    if content:
        print(content, end="", flush=True)
```

### 4. å‚æ•°è°ƒä¼˜

æ ¹æ®åœºæ™¯è°ƒæ•´å‚æ•°ï¼š

```python
# åˆ›æ„å†™ä½œ - é«˜æ¸©åº¦
response = client.chat.completions.create(
    model="gemini-1.5-pro",
    messages=[{"role": "user", "content": "å†™ä¸€é¦–è¯—"}],
    temperature=0.9,
    max_tokens=2048
)

# æŠ€æœ¯é—®ç­” - ä½æ¸©åº¦
response = client.chat.completions.create(
    model="gemini-1.5-pro",
    messages=[{"role": "user", "content": "ä»€ä¹ˆæ˜¯REST API?"}],
    temperature=0.3,
    max_tokens=1024
)
```

---

## æ•…éšœæ’é™¤

### è¿æ¥é”™è¯¯

**é—®é¢˜**: æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
curl http://127.0.0.1:2048/health

# æ£€æŸ¥ç«¯å£æ˜¯å¦æ­£ç¡®
# å¦‚æœä½¿ç”¨è‡ªå®šä¹‰ç«¯å£ï¼Œéœ€è¦ä¿®æ”¹ base_url
```

### è®¤è¯é”™è¯¯

**é—®é¢˜**: 401 Unauthorized

**è§£å†³æ–¹æ¡ˆ**:

```python
# ç¡®ä¿æä¾›äº†æœ‰æ•ˆçš„ API å¯†é’¥
client = OpenAI(
    base_url="http://127.0.0.1:2048/v1",
    api_key="your-valid-api-key"  # ä½¿ç”¨æœ‰æ•ˆå¯†é’¥
)
```

### è¶…æ—¶é”™è¯¯

**é—®é¢˜**: è¯·æ±‚è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**:

```python
# å¢åŠ è¶…æ—¶æ—¶é—´
client = OpenAI(
    base_url="http://127.0.0.1:2048/v1",
    api_key="your-api-key",
    timeout=120.0  # å¢åŠ åˆ° 120 ç§’
)
```

---

## ç›¸å…³æ–‡æ¡£

- [API ä½¿ç”¨æŒ‡å—](api-usage.md) - è¯¦ç»†çš„ API ç«¯ç‚¹è¯´æ˜
- [OpenAI å…¼å®¹æ€§è¯´æ˜](openai-compatibility.md) - å…¼å®¹æ€§å’Œé™åˆ¶
- [æ•…éšœæ’é™¤æŒ‡å—](troubleshooting.md) - å¸¸è§é—®é¢˜è§£å†³

---

å¦‚æœ‰é—®é¢˜æˆ–éœ€è¦æ›´å¤šç¤ºä¾‹ï¼Œè¯·æäº¤ Issueã€‚
